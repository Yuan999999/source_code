{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained Vectors - Neural Network Classifier\n",
    "\n",
    "In this notebook, we try various merging strategies to merge the vectors for image pair inputs and try to predict similarity using a fully connected neural network front end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.layers import Input\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.core import Activation, Dense, Dropout, Lambda\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from scipy import spatial\n",
    "\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/\"\n",
    "IMAGE_DIR = os.path.join(DATA_DIR, \"images_after_crop\")\n",
    "TEST_B_DIR = os.path.join(DATA_DIR, \"pigtest_b\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_SIZE = 2048\n",
    "VECTOR_FILE = os.path.join(\"/vector_data/\", \"resnet-vectors-cropped-images.tsv\")\n",
    "VECTOR_FILE_TEST_B = os.path.join(\"/vector_data/\", \"resnet-vectors-test-b.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_b_triples(image_dir, test_b_dir):\n",
    "    test_b_triples = []\n",
    "    image_names_rev = [x for x in os.listdir(image_dir) if not (x.startswith('.'))]\n",
    "    test_b_names = [x for x in os.listdir(test_b_dir) if not (x.startswith('.'))]\n",
    "    for test_b_name in test_b_names:\n",
    "        for image_name in image_names_rev:\n",
    "            test_b_triples.append((test_b_name, image_name, 0))\n",
    "    return test_b_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pig_triples_new(image_dir):\n",
    "    image_groups = {}\n",
    "    image_names_rev = [x for x in os.listdir(image_dir) if not (x.startswith('.'))]\n",
    "    for image_name in image_names_rev:\n",
    "        base_name = image_name[0:-6]\n",
    "        group_name = base_name[0:2]\n",
    "        if image_groups.has_key(group_name):\n",
    "            image_groups[group_name].append(image_name)\n",
    "        else:\n",
    "            image_groups[group_name] = [image_name]\n",
    "    num_sims = 0\n",
    "    num_difs = 0\n",
    "    image_triples = []\n",
    "    group_list = sorted(list(image_groups.keys()))\n",
    "    for i, g in enumerate(group_list):\n",
    "        if num_sims % 100 == 0:\n",
    "            print(\"Generated {:d} pos + {:d} neg = {:d} total image triples\" \n",
    "                  .format(num_sims, num_sims, 2*num_sims))\n",
    "        images_in_group = image_groups[g]\n",
    "        #sim_pairs_it = ((images_in_group[1],images_in_group[2]),(images_in_group[2],images_in_group[4]))\n",
    "        sim_pairs_it = itertools.combinations(images_in_group, 2)\n",
    "        # for each similar pair, generate a corresponding different pair\n",
    "        for ref_image, sim_image in sim_pairs_it:\n",
    "            image_triples.append((ref_image, sim_image, 1))\n",
    "            num_sims += 1\n",
    "            for j, h in enumerate(group_list):\n",
    "                if j !=i:\n",
    "                    dif_image_candidates = image_groups[group_list[j]]\n",
    "                    for x in range(0,2):\n",
    "                        k = np.random.randint(low=0, high=len(dif_image_candidates), size=1)[0]\n",
    "                        dif_image = dif_image_candidates[k]\n",
    "                        image_triples.append((ref_image, dif_image, 0))\n",
    "                        num_difs += 1\n",
    "                        if num_sims % 1000000 == 0:\n",
    "                            print(\"Generated {:d} pos + {:d} neg = {:d} total image triples\"\n",
    "                            .format(num_sims, num_sims, 2*num_sims))\n",
    "                else:\n",
    "                    break \n",
    "    \n",
    "    np.random.shuffle(image_triples)\n",
    "    #print(image_triples)\n",
    "    print(num_sims)\n",
    "    print(num_difs)\n",
    "    return image_triples\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 pos + 0 neg = 0 total image triples\n",
      "60376\n",
      "1769952\n"
     ]
    }
   ],
   "source": [
    "image_triples = get_pig_triples_new(IMAGE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1830328\n"
     ]
    }
   ],
   "source": [
    "print(len(image_triples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors(vector_file):\n",
    "    vec_dict = {}\n",
    "    fvec = open(vector_file, \"rb\")\n",
    "    for line in fvec:\n",
    "        image_name, image_vec = line.strip().split(\"\\t\")\n",
    "        vec = np.array([float(v) for v in image_vec.split(\",\")])\n",
    "        vec_dict[image_name] = vec\n",
    "    fvec.close()\n",
    "    return vec_dict\n",
    "\n",
    "def train_test_split(triples, splits):\n",
    "    assert sum(splits) == 1.0\n",
    "    split_pts = np.cumsum(np.array([0.] + splits))\n",
    "    indices = np.random.permutation(np.arange(len(triples)))\n",
    "    shuffled_triples = [triples[i] for i in indices]\n",
    "    data_splits = []\n",
    "    for sid in range(len(splits)):\n",
    "        start = int(split_pts[sid] * len(triples))\n",
    "        end = int(split_pts[sid + 1] * len(triples))\n",
    "        data_splits.append(shuffled_triples[start:end])\n",
    "    return data_splits\n",
    "\n",
    "def batch_to_vectors(batch, vec_size, vec_dict):\n",
    "    X1 = np.zeros((len(batch), vec_size))\n",
    "    X2 = np.zeros((len(batch), vec_size))\n",
    "    Y = np.zeros((len(batch), 2))\n",
    "    for tid in range(len(batch)):\n",
    "        X1[tid] = vec_dict[batch[tid][0]]\n",
    "        X2[tid] = vec_dict[batch[tid][1]]\n",
    "        Y[tid] = [1, 0] if batch[tid][2] == 0 else [0, 1]\n",
    "    return ([X1, X2], Y)\n",
    "\n",
    "    \n",
    "def data_generator(triples, vec_size, vec_dict, batch_size=32):\n",
    "    while True:\n",
    "        # shuffle once per batch\n",
    "        indices = np.random.permutation(np.arange(len(triples)))\n",
    "        num_batches = len(triples) // batch_size\n",
    "        for bid in range(num_batches):\n",
    "            batch_indices = indices[bid * batch_size : (bid + 1) * batch_size]\n",
    "            batch = [triples[i] for i in batch_indices]\n",
    "            yield batch_to_vectors(batch, vec_size, vec_dict)\n",
    "\n",
    "\n",
    "def evaluate_model(model_file, test_gen):\n",
    "    model_name = os.path.basename(model_file)\n",
    "    model = load_model(model_file)\n",
    "    print(\"=== Evaluating model: {:s} ===\".format(model_name))\n",
    "    ytrue, ypred = [], []\n",
    "    num_test_steps = len(test_triples) // BATCH_SIZE\n",
    "    for i in range(num_test_steps):\n",
    "        (X1, X2), Y = test_gen.next()\n",
    "        Y_ = model.predict([X1, X2])\n",
    "        ytrue.extend(np.argmax(Y, axis=1).tolist())\n",
    "        ypred.extend(np.argmax(Y_, axis=1).tolist())\n",
    "    accuracy = accuracy_score(ytrue, ypred)\n",
    "    print(\"\\nAccuracy: {:.3f}\".format(accuracy))\n",
    "    print(\"\\nConfusion Matrix\")\n",
    "    print(confusion_matrix(ytrue, ypred))\n",
    "    print(\"\\nClassification Report\")\n",
    "    print(classification_report(ytrue, ypred))\n",
    "    return accuracy\n",
    "\n",
    "def get_model_file(data_dir, vector_name, merge_mode, borf):\n",
    "    return os.path.join(data_dir, \"{:s}-{:s}-{:s}.h5\"\n",
    "                        .format(vector_name, merge_mode, borf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_triple_generator(image_triples, batch_size):\n",
    "    while True:\n",
    "        # loop once per epoch\n",
    "        num_recs = len(image_triples)\n",
    "        #indices = np.random.permutation(np.arange(num_recs))\n",
    "        indices = np.arange(num_recs)\n",
    "        num_batches = num_recs // batch_size\n",
    "        for bid in range(num_batches):\n",
    "            # loop once per batch\n",
    "            batch_indices = indices[bid * batch_size : (bid + 1) * batch_size]\n",
    "            yield [image_triples[i] for i in batch_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_dict = load_vectors(VECTOR_FILE)\n",
    "vec_dict_test_b = load_vectors(VECTOR_FILE_TEST_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('03frame11_c.jpg', '02frame13_c.jpg', 0),\n",
       " ('29frame34_c.jpg', '17frame47_c.jpg', 0),\n",
       " ('21frame52_c.jpg', '20frame31_c.jpg', 0),\n",
       " ('20frame34_c.jpg', '07frame57_c.jpg', 0),\n",
       " ('05frame50_c.jpg', '04frame9_c.jpg', 0),\n",
       " ('15frame46_c.jpg', '10frame64_c.jpg', 0),\n",
       " ('07frame18_c.jpg', '01frame63_c.jpg', 0),\n",
       " ('04frame39_c.jpg', '01frame51_c.jpg', 0),\n",
       " ('13frame25_c.jpg', '06frame21_c.jpg', 0),\n",
       " ('15frame53_c.jpg', '09frame28_c.jpg', 0),\n",
       " ('27frame1_c.jpg', '09frame35_c.jpg', 0),\n",
       " ('28frame57_c.jpg', '15frame59_c.jpg', 0),\n",
       " ('15frame58_c.jpg', '08frame43_c.jpg', 0),\n",
       " ('24frame35_c.jpg', '18frame5_c.jpg', 0),\n",
       " ('16frame61_c.jpg', '16frame33_c.jpg', 1),\n",
       " ('27frame22_c.jpg', '01frame34_c.jpg', 0),\n",
       " ('20frame5_c.jpg', '16frame21_c.jpg', 0),\n",
       " ('04frame16_c.jpg', '04frame14_c.jpg', 1),\n",
       " ('08frame61_c.jpg', '05frame56_c.jpg', 0),\n",
       " ('28frame13_c.jpg', '09frame6_c.jpg', 0),\n",
       " ('03frame20_c.jpg', '01frame35_c.jpg', 0),\n",
       " ('06frame12_c.jpg', '04frame61_c.jpg', 0),\n",
       " ('16frame31_c.jpg', '02frame59_c.jpg', 0),\n",
       " ('20frame50_c.jpg', '14frame38_c.jpg', 0),\n",
       " ('19frame35_c.jpg', '02frame56_c.jpg', 0),\n",
       " ('08frame53_c.jpg', '03frame40_c.jpg', 0),\n",
       " ('08frame14_c.jpg', '01frame34_c.jpg', 0),\n",
       " ('13frame5_c.jpg', '02frame55_c.jpg', 0),\n",
       " ('24frame33_c.jpg', '12frame51_c.jpg', 0),\n",
       " ('17frame46_c.jpg', '12frame63_c.jpg', 0),\n",
       " ('28frame50_c.jpg', '18frame39_c.jpg', 0),\n",
       " ('20frame46_c.jpg', '15frame48_c.jpg', 0),\n",
       " ('20frame41_c.jpg', '07frame9_c.jpg', 0),\n",
       " ('12frame58_c.jpg', '08frame42_c.jpg', 0),\n",
       " ('26frame64_c.jpg', '23frame49_c.jpg', 0),\n",
       " ('28frame25_c.jpg', '12frame0_c.jpg', 0),\n",
       " ('26frame34_c.jpg', '01frame64_c.jpg', 0),\n",
       " ('23frame35_c.jpg', '23frame9_c.jpg', 1),\n",
       " ('29frame19_c.jpg', '26frame23_c.jpg', 0),\n",
       " ('25frame34_c.jpg', '13frame63_c.jpg', 0),\n",
       " ('24frame20_c.jpg', '19frame24_c.jpg', 0),\n",
       " ('26frame0_c.jpg', '12frame31_c.jpg', 0),\n",
       " ('21frame0_c.jpg', '16frame13_c.jpg', 0),\n",
       " ('21frame2_c.jpg', '07frame55_c.jpg', 0),\n",
       " ('23frame21_c.jpg', '06frame2_c.jpg', 0),\n",
       " ('29frame57_c.jpg', '29frame4_c.jpg', 1),\n",
       " ('09frame60_c.jpg', '01frame25_c.jpg', 0),\n",
       " ('26frame52_c.jpg', '04frame12_c.jpg', 0),\n",
       " ('28frame34_c.jpg', '15frame64_c.jpg', 0),\n",
       " ('05frame63_c.jpg', '02frame60_c.jpg', 0),\n",
       " ('17frame56_c.jpg', '05frame39_c.jpg', 0),\n",
       " ('21frame3_c.jpg', '08frame24_c.jpg', 0),\n",
       " ('26frame4_c.jpg', '16frame49_c.jpg', 0),\n",
       " ('13frame3_c.jpg', '06frame36_c.jpg', 0),\n",
       " ('07frame26_c.jpg', '03frame62_c.jpg', 0),\n",
       " ('23frame52_c.jpg', '04frame62_c.jpg', 0),\n",
       " ('04frame22_c.jpg', '01frame44_c.jpg', 0),\n",
       " ('18frame21_c.jpg', '03frame44_c.jpg', 0),\n",
       " ('28frame15_c.jpg', '03frame2_c.jpg', 0),\n",
       " ('17frame56_c.jpg', '10frame17_c.jpg', 0),\n",
       " ('27frame55_c.jpg', '14frame42_c.jpg', 0),\n",
       " ('30frame51_c.jpg', '22frame40_c.jpg', 0),\n",
       " ('23frame28_c.jpg', '20frame38_c.jpg', 0),\n",
       " ('22frame49_c.jpg', '13frame34_c.jpg', 0),\n",
       " ('23frame25_c.jpg', '01frame22_c.jpg', 0),\n",
       " ('29frame34_c.jpg', '14frame19_c.jpg', 0),\n",
       " ('22frame53_c.jpg', '02frame61_c.jpg', 0),\n",
       " ('14frame35_c.jpg', '01frame24_c.jpg', 0),\n",
       " ('10frame58_c.jpg', '10frame33_c.jpg', 1),\n",
       " ('30frame2_c.jpg', '21frame36_c.jpg', 0),\n",
       " ('25frame21_c.jpg', '06frame4_c.jpg', 0),\n",
       " ('24frame48_c.jpg', '10frame14_c.jpg', 0),\n",
       " ('30frame54_c.jpg', '04frame9_c.jpg', 0),\n",
       " ('25frame2_c.jpg', '23frame42_c.jpg', 0),\n",
       " ('19frame46_c.jpg', '18frame7_c.jpg', 0),\n",
       " ('16frame2_c.jpg', '12frame9_c.jpg', 0),\n",
       " ('19frame15_c.jpg', '07frame53_c.jpg', 0),\n",
       " ('15frame41_c.jpg', '09frame38_c.jpg', 0),\n",
       " ('22frame31_c.jpg', '06frame26_c.jpg', 0),\n",
       " ('23frame41_c.jpg', '11frame8_c.jpg', 0),\n",
       " ('27frame64_c.jpg', '01frame53_c.jpg', 0),\n",
       " ('30frame11_c.jpg', '14frame61_c.jpg', 0),\n",
       " ('24frame50_c.jpg', '06frame39_c.jpg', 0),\n",
       " ('13frame52_c.jpg', '10frame2_c.jpg', 0),\n",
       " ('12frame49_c.jpg', '04frame43_c.jpg', 0),\n",
       " ('11frame3_c.jpg', '07frame34_c.jpg', 0),\n",
       " ('27frame17_c.jpg', '15frame54_c.jpg', 0),\n",
       " ('23frame2_c.jpg', '05frame8_c.jpg', 0),\n",
       " ('23frame36_c.jpg', '08frame38_c.jpg', 0),\n",
       " ('22frame55_c.jpg', '05frame61_c.jpg', 0),\n",
       " ('16frame38_c.jpg', '10frame45_c.jpg', 0),\n",
       " ('23frame48_c.jpg', '20frame31_c.jpg', 0),\n",
       " ('24frame33_c.jpg', '03frame20_c.jpg', 0),\n",
       " ('23frame14_c.jpg', '11frame50_c.jpg', 0),\n",
       " ('23frame55_c.jpg', '11frame49_c.jpg', 0),\n",
       " ('30frame15_c.jpg', '05frame38_c.jpg', 0),\n",
       " ('18frame11_c.jpg', '16frame38_c.jpg', 0),\n",
       " ('26frame61_c.jpg', '07frame15_c.jpg', 0),\n",
       " ('22frame20_c.jpg', '19frame44_c.jpg', 0),\n",
       " ('22frame2_c.jpg', '18frame8_c.jpg', 0)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triples_batch_gen = image_triple_generator(image_triples, 100)\n",
    "triples_batch_gen.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('17frame61_c.jpg', '07frame42_c.jpg', 0),\n",
       " ('27frame17_c.jpg', '02frame58_c.jpg', 0),\n",
       " ('21frame12_c.jpg', '15frame3_c.jpg', 0),\n",
       " ('09frame60_c.jpg', '07frame16_c.jpg', 0),\n",
       " ('19frame13_c.jpg', '16frame7_c.jpg', 0),\n",
       " ('21frame45_c.jpg', '21frame63_c.jpg', 1),\n",
       " ('17frame29_c.jpg', '14frame18_c.jpg', 0),\n",
       " ('18frame8_c.jpg', '09frame29_c.jpg', 0),\n",
       " ('20frame50_c.jpg', '02frame35_c.jpg', 0),\n",
       " ('19frame49_c.jpg', '14frame32_c.jpg', 0),\n",
       " ('24frame6_c.jpg', '22frame28_c.jpg', 0),\n",
       " ('22frame6_c.jpg', '18frame18_c.jpg', 0),\n",
       " ('23frame26_c.jpg', '04frame33_c.jpg', 0),\n",
       " ('10frame23_c.jpg', '01frame29_c.jpg', 0),\n",
       " ('19frame31_c.jpg', '13frame17_c.jpg', 0),\n",
       " ('27frame47_c.jpg', '10frame35_c.jpg', 0),\n",
       " ('29frame59_c.jpg', '03frame15_c.jpg', 0),\n",
       " ('17frame61_c.jpg', '14frame37_c.jpg', 0),\n",
       " ('22frame59_c.jpg', '05frame48_c.jpg', 0),\n",
       " ('22frame40_c.jpg', '10frame32_c.jpg', 0),\n",
       " ('06frame58_c.jpg', '05frame24_c.jpg', 0),\n",
       " ('20frame51_c.jpg', '10frame62_c.jpg', 0),\n",
       " ('24frame18_c.jpg', '22frame2_c.jpg', 0),\n",
       " ('18frame57_c.jpg', '01frame41_c.jpg', 0),\n",
       " ('16frame5_c.jpg', '02frame22_c.jpg', 0),\n",
       " ('08frame12_c.jpg', '05frame57_c.jpg', 0),\n",
       " ('12frame5_c.jpg', '02frame62_c.jpg', 0),\n",
       " ('17frame63_c.jpg', '09frame13_c.jpg', 0),\n",
       " ('29frame53_c.jpg', '14frame2_c.jpg', 0),\n",
       " ('16frame39_c.jpg', '08frame31_c.jpg', 0),\n",
       " ('22frame21_c.jpg', '14frame61_c.jpg', 0),\n",
       " ('23frame22_c.jpg', '19frame63_c.jpg', 0),\n",
       " ('28frame25_c.jpg', '22frame6_c.jpg', 0),\n",
       " ('28frame37_c.jpg', '23frame12_c.jpg', 0),\n",
       " ('10frame52_c.jpg', '07frame36_c.jpg', 0),\n",
       " ('28frame53_c.jpg', '06frame14_c.jpg', 0),\n",
       " ('25frame24_c.jpg', '05frame41_c.jpg', 0),\n",
       " ('18frame6_c.jpg', '14frame2_c.jpg', 0),\n",
       " ('29frame27_c.jpg', '16frame15_c.jpg', 0),\n",
       " ('13frame16_c.jpg', '01frame30_c.jpg', 0),\n",
       " ('28frame59_c.jpg', '24frame34_c.jpg', 0),\n",
       " ('23frame13_c.jpg', '05frame61_c.jpg', 0),\n",
       " ('23frame54_c.jpg', '10frame52_c.jpg', 0),\n",
       " ('15frame18_c.jpg', '15frame56_c.jpg', 1),\n",
       " ('16frame34_c.jpg', '06frame43_c.jpg', 0),\n",
       " ('27frame63_c.jpg', '08frame56_c.jpg', 0),\n",
       " ('26frame64_c.jpg', '21frame50_c.jpg', 0),\n",
       " ('28frame56_c.jpg', '08frame9_c.jpg', 0),\n",
       " ('26frame23_c.jpg', '18frame3_c.jpg', 0),\n",
       " ('21frame39_c.jpg', '16frame32_c.jpg', 0),\n",
       " ('17frame8_c.jpg', '03frame23_c.jpg', 0),\n",
       " ('14frame40_c.jpg', '02frame64_c.jpg', 0),\n",
       " ('28frame3_c.jpg', '02frame45_c.jpg', 0),\n",
       " ('13frame25_c.jpg', '08frame37_c.jpg', 0),\n",
       " ('07frame53_c.jpg', '07frame28_c.jpg', 1),\n",
       " ('06frame46_c.jpg', '05frame23_c.jpg', 0),\n",
       " ('10frame58_c.jpg', '09frame31_c.jpg', 0),\n",
       " ('20frame12_c.jpg', '11frame18_c.jpg', 0),\n",
       " ('12frame61_c.jpg', '05frame20_c.jpg', 0),\n",
       " ('13frame3_c.jpg', '11frame2_c.jpg', 0),\n",
       " ('04frame58_c.jpg', '02frame61_c.jpg', 0),\n",
       " ('30frame45_c.jpg', '29frame42_c.jpg', 0),\n",
       " ('25frame44_c.jpg', '13frame15_c.jpg', 0),\n",
       " ('13frame10_c.jpg', '01frame23_c.jpg', 0),\n",
       " ('26frame3_c.jpg', '22frame7_c.jpg', 0),\n",
       " ('19frame5_c.jpg', '14frame32_c.jpg', 0),\n",
       " ('26frame35_c.jpg', '02frame3_c.jpg', 0),\n",
       " ('17frame58_c.jpg', '08frame4_c.jpg', 0),\n",
       " ('17frame4_c.jpg', '17frame10_c.jpg', 1),\n",
       " ('13frame44_c.jpg', '03frame27_c.jpg', 0),\n",
       " ('16frame7_c.jpg', '03frame23_c.jpg', 0),\n",
       " ('22frame49_c.jpg', '09frame42_c.jpg', 0),\n",
       " ('12frame37_c.jpg', '02frame40_c.jpg', 0),\n",
       " ('19frame33_c.jpg', '13frame49_c.jpg', 0),\n",
       " ('26frame25_c.jpg', '06frame16_c.jpg', 0),\n",
       " ('26frame57_c.jpg', '23frame36_c.jpg', 0),\n",
       " ('10frame22_c.jpg', '09frame55_c.jpg', 0),\n",
       " ('24frame7_c.jpg', '23frame4_c.jpg', 0),\n",
       " ('29frame59_c.jpg', '23frame31_c.jpg', 0),\n",
       " ('28frame13_c.jpg', '28frame54_c.jpg', 1),\n",
       " ('22frame27_c.jpg', '22frame50_c.jpg', 1),\n",
       " ('26frame48_c.jpg', '17frame53_c.jpg', 0),\n",
       " ('28frame7_c.jpg', '02frame34_c.jpg', 0),\n",
       " ('11frame3_c.jpg', '04frame19_c.jpg', 0),\n",
       " ('29frame60_c.jpg', '17frame36_c.jpg', 0),\n",
       " ('07frame49_c.jpg', '07frame1_c.jpg', 1),\n",
       " ('12frame12_c.jpg', '11frame15_c.jpg', 0),\n",
       " ('30frame47_c.jpg', '24frame54_c.jpg', 0),\n",
       " ('17frame5_c.jpg', '13frame8_c.jpg', 0),\n",
       " ('17frame4_c.jpg', '07frame27_c.jpg', 0),\n",
       " ('24frame10_c.jpg', '15frame56_c.jpg', 0),\n",
       " ('20frame51_c.jpg', '08frame12_c.jpg', 0),\n",
       " ('27frame31_c.jpg', '04frame49_c.jpg', 0),\n",
       " ('11frame11_c.jpg', '08frame24_c.jpg', 0),\n",
       " ('21frame46_c.jpg', '09frame13_c.jpg', 0),\n",
       " ('16frame47_c.jpg', '05frame34_c.jpg', 0),\n",
       " ('24frame43_c.jpg', '18frame37_c.jpg', 0),\n",
       " ('25frame45_c.jpg', '23frame18_c.jpg', 0),\n",
       " ('12frame54_c.jpg', '08frame13_c.jpg', 0),\n",
       " ('24frame36_c.jpg', '13frame38_c.jpg', 0)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triples_get = triples_batch_gen.next()\n",
    "triples_get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17frame61_c.jpg\n",
      "07frame42_c.jpg\n",
      "02frame58_c.jpg\n",
      "0.323475680361\n",
      "0.341245988623\n"
     ]
    }
   ],
   "source": [
    "ref_image = triples_get[0][0]\n",
    "print(ref_image)\n",
    "sim_image = triples_get[0][1]\n",
    "print(sim_image)\n",
    "dif_image = triples_get[1][1]\n",
    "print(dif_image)\n",
    "cos_dist_sim = spatial.distance.cosine(vec_dict[ref_image], vec_dict[sim_image])\n",
    "cos_dist_dif = spatial.distance.cosine(vec_dict[ref_image], vec_dict[dif_image])\n",
    "print(cos_dist_sim)\n",
    "print(cos_dist_dif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5751000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('1011.JPG', '02frame46_c.jpg', 0),\n",
       " ('1011.JPG', '04frame48_c.jpg', 0),\n",
       " ('1011.JPG', '30frame10_c.jpg', 0),\n",
       " ('1011.JPG', '14frame50_c.jpg', 0)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_b_triples = get_test_b_triples(IMAGE_DIR, TEST_B_DIR)\n",
    "print(len(test_b_triples))\n",
    "\n",
    "triples_batch_gen = image_triple_generator(test_b_triples, 4)\n",
    "triples_batch_gen.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1011.JPG', '22frame33_c.jpg', 0),\n",
       " ('1011.JPG', '08frame19_c.jpg', 0),\n",
       " ('1011.JPG', '01frame55_c.jpg', 0),\n",
       " ('1011.JPG', '08frame11_c.jpg', 0)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triples_batch_gen.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare and Extract Common Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1738811 73213 18304\n"
     ]
    }
   ],
   "source": [
    "train_triples, val_triples, test_triples = train_test_split(image_triples, \n",
    "                                                            splits=[0.95, 0.04, 0.01])\n",
    "print(len(train_triples), len(val_triples), len(test_triples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet 50 Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = data_generator(train_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "val_gen = data_generator(val_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input: Elementwise Cosine Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,) (10,)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "def cosine_distance(vecs, normalize=False):\n",
    "    x, y = vecs\n",
    "    if normalize:\n",
    "        x = K.l2_normalize(x, axis=0)\n",
    "        y = K.l2_normalize(x, axis=0)\n",
    "    return K.prod(K.stack([x, y], axis=1), axis=1)\n",
    "\n",
    "def cosine_distance_output_shape(shapes):\n",
    "    return shapes[0]\n",
    "\n",
    "vecs = [np.random.random((10,)), np.random.random((10,))]\n",
    "print(vecs[0].shape, vecs[1].shape)\n",
    "s = cosine_distance(vecs)\n",
    "print(s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = Input(shape=(VECTOR_SIZE,))\n",
    "input_2 = Input(shape=(VECTOR_SIZE,))\n",
    "merged = Lambda(cosine_distance, \n",
    "                  output_shape=cosine_distance_output_shape)([input_1, input_2])\n",
    "\n",
    "fc1 = Dense(512, kernel_initializer=\"glorot_uniform\")(merged)\n",
    "fc1 = Dropout(0.2)(fc1)\n",
    "fc1 = Activation(\"relu\")(fc1)\n",
    "\n",
    "fc2 = Dense(128, kernel_initializer=\"glorot_uniform\")(fc1)\n",
    "fc2 = Dropout(0.2)(fc2)\n",
    "fc2 = Activation(\"relu\")(fc2)\n",
    "\n",
    "pred = Dense(2, kernel_initializer=\"glorot_uniform\")(fc2)\n",
    "pred = Activation(\"softmax\")(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 2048)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 2048)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, 2048)          0           input_1[0][0]                    \n",
      "                                                                   input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 512)           1049088     lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 512)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 512)           0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 128)           65664       activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 128)           0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 128)           0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 2)             258         activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 2)             0           dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 1,115,010\n",
      "Trainable params: 1,115,010\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[input_1, input_2], outputs=pred)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 4325/54337 [=>............................] - ETA: 847s - loss: 0.5328 - acc: 0.9669"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-7ae402fa993c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_steps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                               callbacks=[checkpoint])\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2040\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2041\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2042\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1760\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_model_name = get_model_file(\"/output/\", \"resnet50_cropped_large_train\", \"dot\", \"best\")\n",
    "checkpoint = ModelCheckpoint(best_model_name, save_best_only=True)\n",
    "train_steps_per_epoch = len(train_triples) // BATCH_SIZE\n",
    "val_steps_per_epoch = len(val_triples) // BATCH_SIZE\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_steps_per_epoch, \n",
    "                              epochs=NUM_EPOCHS, \n",
    "                              validation_data=val_gen, validation_steps=val_steps_per_epoch,\n",
    "                              callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcd8037c1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"r\", label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"r\", label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluating model: resnet50_cropped_hard_train-dot-final.h5 ===\n",
      "\n",
      "Accuracy: 0.983\n",
      "\n",
      "Confusion Matrix\n",
      "[[11233   347]\n",
      " [   52 11504]]\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.98     11580\n",
      "          1       0.97      1.00      0.98     11556\n",
      "\n",
      "avg / total       0.98      0.98      0.98     23136\n",
      "\n",
      "=== Evaluating model: resnet50_cropped_hard_train-dot-best.h5 ===\n",
      "\n",
      "Accuracy: 0.982\n",
      "\n",
      "Confusion Matrix\n",
      "[[11223   355]\n",
      " [   63 11495]]\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.97      0.98     11578\n",
      "          1       0.97      0.99      0.98     11558\n",
      "\n",
      "avg / total       0.98      0.98      0.98     23136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_model_name = get_model_file(\"/output/\", \"resnet50_cropped_hard_train\", \"dot\", \"final\")\n",
    "#best_model_name = get_model_file(\"/output/\", \"resnet50_cropped\", \"dot\", \"best\")\n",
    "model.save(final_model_name)\n",
    "test_gen = data_generator(test_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "final_accuracy = evaluate_model(final_model_name, test_gen)\n",
    "\n",
    "test_gen = data_generator(test_triples, VECTOR_SIZE, vec_dict, BATCH_SIZE)\n",
    "best_accuracy = evaluate_model(best_model_name, test_gen)\n",
    "\n",
    "#scores[1, 1] = best_accuracy if best_accuracy > final_accuracy else final_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def evaluate_test_b_simple_ave(model_file, image_dir, test_b_dir, vec_size, vec_dict_test_b, vec_dict, batch_size):\n",
    "    model_name = os.path.basename(model_file)\n",
    "    model = load_model(model_file)\n",
    "    print(\"=== Evaluating model test a: {:s} ===\".format(model_name))\n",
    "    image_names_rev = [x for x in os.listdir(image_dir) if not (x.startswith('.'))]\n",
    "    test_b_names = [x for x in os.listdir(test_b_dir) if not (x.startswith('.'))]\n",
    "    X1 = np.zeros((len(image_names_rev), vec_size))\n",
    "    X2 = np.zeros((len(image_names_rev), vec_size))\n",
    "    #Y = np.zeros((len(batch), 2))\n",
    "    #test_b_names_new = []\n",
    "    #image_names_new = []\n",
    "    ypred = []\n",
    "    for j, test_b_name in enumerate(test_b_names):\n",
    "        test_b_names_new = []\n",
    "        image_names_new = []\n",
    "        for i, image_name in enumerate(image_names_rev):\n",
    "            X1[i] = vec_dict_test_b[test_b_name]\n",
    "            X2[i] = vec_dict[image_name]\n",
    "            test_b_names_new.append(test_b_name[0:-4])\n",
    "            image_names_new.append(image_name[0:-4])\n",
    "        Y_ = model.predict([X1, X2])\n",
    "        Y_s = [x[1] for x in Y_] \n",
    "        #ypred.extend((Y_s))\n",
    "\n",
    "        DF = pd.DataFrame({\"probability\": Y_s, \"ImageGroup\": image_names_new,\n",
    "              \"test_image_ID\": test_b_names_new\n",
    "              })\n",
    "        DF = DF[['test_image_ID', 'ImageGroup', 'probability']]\n",
    "\n",
    "        DF.to_csv(\"/output/test_b_cropped_hard_train_f.csv\",\n",
    "                        sep=',', encoding=\"utf-8\", index = False,\n",
    "                        header = False, mode = \"a\")\n",
    "        if j%100 ==0:\n",
    "            print(\"the %d test image is in processing\" %j)\n",
    "\n",
    "    return Y_s, test_b_names_new,image_names_new\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluating model test a: resnet50_cropped_hard_train-dot-final.h5 ===\n",
      "the 0 test image is in processing\n",
      "the 100 test image is in processing\n",
      "the 200 test image is in processing\n",
      "the 300 test image is in processing\n",
      "the 400 test image is in processing\n",
      "the 500 test image is in processing\n",
      "the 600 test image is in processing\n",
      "the 700 test image is in processing\n",
      "the 800 test image is in processing\n",
      "the 900 test image is in processing\n",
      "the 1000 test image is in processing\n",
      "the 1100 test image is in processing\n",
      "the 1200 test image is in processing\n",
      "the 1300 test image is in processing\n",
      "the 1400 test image is in processing\n",
      "the 1500 test image is in processing\n",
      "the 1600 test image is in processing\n",
      "the 1700 test image is in processing\n",
      "the 1800 test image is in processing\n",
      "the 1900 test image is in processing\n",
      "the 2000 test image is in processing\n",
      "the 2100 test image is in processing\n",
      "the 2200 test image is in processing\n",
      "the 2300 test image is in processing\n",
      "the 2400 test image is in processing\n",
      "the 2500 test image is in processing\n",
      "the 2600 test image is in processing\n",
      "the 2700 test image is in processing\n",
      "the 2800 test image is in processing\n",
      "the 2900 test image is in processing\n"
     ]
    }
   ],
   "source": [
    "ypred, test_b_names, image_names = evaluate_test_b_simple_ave(final_model_name,IMAGE_DIR, TEST_B_DIR, VECTOR_SIZE, vec_dict_test_b, vec_dict, BATCH_SIZE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
